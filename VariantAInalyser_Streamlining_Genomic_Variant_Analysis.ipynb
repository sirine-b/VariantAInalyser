{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 11427297,
          "sourceType": "datasetVersion",
          "datasetId": 7156982
        }
      ],
      "dockerImageVersionId": 31012,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ§¬ **Introduction**\n",
        "\n",
        "Welcome to VariantAInalyser !\n",
        "\n",
        "VariantAInalyser is a comprehensive all-in-one platform that combines traditional bioinformatics with generative AI to streamline genomic variant analysis from VCF files, eliminating the need to juggle multiple specialised tools.\n",
        "\n",
        "## ðŸ‘©ðŸ»â€ðŸ”¬ **The Challenge**\n",
        "\n",
        "Genomic variants are essential biomarkers for understanding diseases, drug responses, and creating personalised treatment plans. However, traditional analysis workflows force researchers to:\n",
        "\n",
        "- Switch between multiple disconnected tools (VCF parsers, annotation software, database interfaces)\n",
        "- Master different user interfaces and data formats\n",
        "- Manually integrate results across platforms\n",
        "- Spend valuable time on technical tasks rather than interpretation\n",
        "\n",
        "This fragmented approach creates inefficiencies, increases the potential for errors, and significantly extends analysis time.\n",
        "\n",
        "## ðŸ’¡ **The Solution: VariantAInalyser!**\n",
        "\n",
        "VariantAInalyser revolutionises genomic analysis by unifying the entire workflow in a single, intuitive interface. This integrated pipeline:\n",
        "\n",
        "- **Consolidates multiple tools into one platform**, eliminating the need to switch between systems\n",
        "- **Automates the complete workflow** from raw VCF data to clinical interpretation\n",
        "- **Requires minimal technical expertise** to operate effectively\n",
        "\n",
        "Researchers and clinicians can now:\n",
        "- Process VCF files to extract critical variant data\n",
        "- Run SegmentNT analysis to identify genomic regions\n",
        "- Query ClinVar for clinical significance\n",
        "- Generate comprehensive reports\n",
        "- Ask questions in natural language\n",
        "\n",
        "All without ever leaving the interface or needing to reformat data between tools!\n",
        "\n",
        "## ðŸ¤– **Generative AI Capabilities**\n",
        "\n",
        "VariantAInalyser's unified approach leverages cutting-edge AI to replace what traditionally required multiple specialised tools:\n",
        "\n",
        "- **Retrieval Augmented Generation**: VariantAInalyser combines the power of Google's Gemini 2.0 Flash model with contextual retrieval from genomic data. As shown in the methods defined within the ScientificTextGenerator class (i.e. generate_report(), ask_agent(), and generate_comparision()), the system dynamically retrieves relevant genomic information from the analysis pipeline and integrates it into the prompt, enabling Gemini to provide more accurate and contextually relevant responses based on the specific variants being analysed.\n",
        "\n",
        "- **Grounding**: Ensures that Gemini's responses are firmly anchored in the actual genomic data processed by the system rather than generic information. The implementation binds the AI to concrete facts from VCF files, ClinVar database results, and SegmentNT predictions, preventing hallucinations and ensuring scientific accuracy in the generated reports. This grounding mechanism creates a direct link between specific variant characteristics and the AI's interpretations of their clinical significance.\n",
        "\n",
        "- **Document Understanding**: VariantAInalyser demonstrates strong document understanding by parsing and extracting key information from complex genomic data files (like VCFs). It leverages bioinformatics libraries (pysam and BioPython) to preprocess and structure the data, enabling the LLM to reason about the variants and their significance.\n",
        "\n",
        "- **Structured Output Generation**: The pipeline automatically produces organised and clinically relevant reports from raw VCF input, SegmentNT outputs and queried ClinVar data  in a way that's ready for clinical review. The LLM is prompted to generate responses in a controlled, consistent format, making the results easy to interpret and use.\n",
        "\n",
        "\n",
        "## ðŸ **Getting Started**\n",
        "\n",
        "Before using VariantAInalyser, you'll need:\n",
        "\n",
        "1. **Google API key**\n",
        "   - Generate it from [AI Studio](https://aistudio.google.com/app/apikey)\n",
        "   - Add to the designated field in the interface\n",
        "\n",
        "2. **ClinVar API key** (optional)\n",
        "   - Create a free [NCBI account](https://account.ncbi.nlm.nih.gov/signup/?back_url=https%3A%2F%2Fwww.ncbi.nlm.nih.gov%2F)\n",
        "   - Navigate to \"Account Settings\"\n",
        "   - Generate an API key in the \"API Key Management\" section\n",
        "   - Add to the corresponding field in the interface\n",
        "\n",
        "ðŸ—’ï¸ **Note**: No worries if you don't have a ClinVar API key, you will still be able to use the VariantAInalyser interface. The ClinVar API key helps avoid rate limiting for multiple queries, but for typical use cases, the system should work fine without it :)\n"
      ],
      "metadata": {
        "id": "7PGs6yisYYuF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## âš™ï¸ **Set-Up and Configuration**\n",
        "\n",
        "This section **installs required packages**, and **imports libraries**, and **configures logging** to track the execution of the pipeline and diagnose any issues that might occur.\n"
      ],
      "metadata": {
        "id": "uz4mRTnQYYuG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Install Required Packages\n",
        "\n",
        "!pip install google-generativeai --upgrade\n",
        "!pip install biopython\n",
        "!pip install pysam\n",
        "!pip install transformers\n",
        "!pip install matplotlib seaborn\n",
        "!pip install ipywidgets\n",
        "\n",
        "print(\"\\n\", \"-\" * 75)\n",
        "print(\"\\n âš™ï¸ Required packages were successfully intalled !\")\n",
        "\n",
        "## Import Libraries\n",
        "\n",
        "import json\n",
        "import os\n",
        "from datetime import datetime\n",
        "import re\n",
        "import tempfile\n",
        "import gzip\n",
        "from typing import Dict, Any, List, Optional\n",
        "import logging\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import requests\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML, clear_output, Markdown\n",
        "from Bio import SeqIO\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import pysam\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "import transformers\n",
        "\n",
        "print(\"\\n\", \"-\" * 75)\n",
        "print(\"\\n âš™ï¸ Required libraries were successfully imported !\")\n",
        "\n",
        "## Set Up Logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "logger = logging.getLogger(\"VariantAnalysisPipeline\")\n",
        "\n",
        "print(\"\\n\", \"-\" * 75)\n",
        "print(\"\\n âš™ï¸ Logging was successfully configured !\")"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-21T02:55:36.588833Z",
          "iopub.execute_input": "2025-04-21T02:55:36.589187Z",
          "iopub.status.idle": "2025-04-21T02:56:29.258559Z",
          "shell.execute_reply.started": "2025-04-21T02:55:36.589155Z",
          "shell.execute_reply": "2025-04-21T02:56:29.257561Z"
        },
        "id": "IW2tqmu9YYuG"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ’» Definition of Core Classes\n",
        "\n",
        "In this section, we will be defining the classes that implement the core functionality of our VariantAInalyser.\n",
        "\n",
        "### 1. ScientificTextGenerator ðŸ–º\n",
        "This class serves as the bridge between raw genomic data and human-readable insights:\n",
        "\n",
        "\n",
        "- Leverages Google's Gemini 2.0 Flah model\n",
        "\n",
        "- Constructs prompts that combine variant data (from VCF files), genomic classifications (from segmentNT results), and queried ClinVar data\n",
        "\n",
        "- Generates detailed scientific explanations tailored to the user's specific questions\n",
        "\n",
        "### 2. VariantAnalysisPipeline ðŸ“ˆ\n",
        "This class corresponds to the core analysis engine that orchestrates the entire workflow:\n",
        "\n",
        "\n",
        "- Extracts variant information from VCF files\n",
        "\n",
        "- Loads and runs the SegmentNT model to identify genomic regions\n",
        "\n",
        "- Queries the ClinVar database for clinical significance\n",
        "\n",
        "- Integrates all results into a comprehensive analysis\n",
        "\n",
        "### 3. VariantAnalysisUI ðŸ‘©ðŸ»â€ðŸ’»\n",
        "This class defines the interactive interface that makes the system accessible to users:\n",
        "\n",
        "\n",
        "- Provides intuitive controls for uploading VCF files and selecting variants\n",
        "\n",
        "- Displays variant information in a structured format\n",
        "\n",
        "- Offers a chat-like interface for natural language interaction\n",
        "\n",
        "- Allows downloading of results and conversation history"
      ],
      "metadata": {
        "id": "jNmQmiERYYuG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ScientificTextGenerator:\n",
        "    \"\"\"\n",
        "    A class for generating scientific text reports about genomic variants\n",
        "    using Generative AI (Google's Gemini model).\n",
        "\n",
        "    This class handles connection to the Gemini API and provides methods for\n",
        "    generating various types of genomic reports and answering variant-related queries.\n",
        "\n",
        "    Attributes:\n",
        "        client: Google Generative AI client for making API calls\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, api_key: str):\n",
        "        \"\"\"\n",
        "        Initialize the text generator with API credentials.\n",
        "\n",
        "        Args:\n",
        "            api_key (str): Google API key for Gemini access. If None, will attempt\n",
        "                          to use GOOGLE_API_KEY environment variable.\n",
        "\n",
        "        Raises:\n",
        "            ValueError: If no API key is provided and no environment variable is set.\n",
        "        \"\"\"\n",
        "        # Check for API key in arguments or environment variables\n",
        "        if api_key:\n",
        "            os.environ[\"GOOGLE_API_KEY\"] = api_key\n",
        "            self.client = genai.Client(api_key=api_key)\n",
        "        elif \"GOOGLE_API_KEY\" in os.environ:\n",
        "            self.client = genai.Client(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
        "        else:\n",
        "            raise ValueError(\"No API key provided. Please provide an API key or set GOOGLE_API_KEY environment variable.\")\n",
        "\n",
        "    def generate_report(self, variant_data: Dict, clinvar_data: Dict,\n",
        "                       segment_nt_classes: Dict, protein_change: str,\n",
        "                       gene_name: str, user_question: str) -> str:\n",
        "        \"\"\"\n",
        "        Generate a scientific report about a variant based on analyzed data.\n",
        "\n",
        "        Combines information from multiple sources to create a comprehensive\n",
        "        clinical report tailored to the user's specific question.\n",
        "\n",
        "        Args:\n",
        "            variant_data (Dict): Dictionary containing basic variant information\n",
        "            clinvar_data (Dict): Dictionary containing clinical significance data from ClinVar\n",
        "            segment_nt_classes (Dict): Dictionary of genomic classes with probabilities from SegmentNT\n",
        "            protein_change (str): String describing the protein change caused by the variant\n",
        "            gene_name (str): Name of the gene containing the variant\n",
        "            user_question (str): User's specific question about the variant\n",
        "\n",
        "        Returns:\n",
        "            str: Detailed scientific report addressing the user's question about the variant\n",
        "\n",
        "        Raises:\n",
        "            Exception: If there's an error generating the report via the Gemini API\n",
        "        \"\"\"\n",
        "        # Format input data for the prompt\n",
        "        input_data = f\"Variant Data: {variant_data}\\n\"\n",
        "\n",
        "        # Add optional data if available\n",
        "        if segment_nt_classes:\n",
        "            input_data += f\"Genomic Classes: {segment_nt_classes}\\n\"\n",
        "        if clinvar_data:\n",
        "            input_data += f\"ClinVar Data: {clinvar_data}\\n\"\n",
        "        if protein_change:\n",
        "            input_data += f\"Protein Change: {protein_change}\\n\"\n",
        "        if gene_name:\n",
        "            input_data += f\"Gene: {gene_name}\\n\"\n",
        "\n",
        "        # Craft the prompt for Gemini with specific instructions\n",
        "        prompt = f\"\"\"\n",
        "            You are an AI agent, helping out a biologist. The user asked the following question: \"{user_question}\".\n",
        "            Based on the question and the provided analysis results below, please generate a clinical report for the variant.\n",
        "\n",
        "            Analysis Results:\n",
        "            {input_data}\n",
        "\n",
        "            Make sure the report is well structured, professional, and accurate. Provide helpful technical information and\n",
        "            make sure to combine/relate together data from vcf file, genomic results (from segmentNT) and clinvar queries to give\n",
        "            most exhaustive, insightful and clinically useful report.\n",
        "            Address the user's question directly.\n",
        "            Specifically mention the identified genomic classes and their associated probabilities\n",
        "            given in the current_analysis[genomic_classes_with_prob] (exon, intron, 5UTR, slicing region ... etc) and their relevance to the variant.\n",
        "        \"\"\"\n",
        "\n",
        "        # Generate report using Gemini API\n",
        "        try:\n",
        "            # Initialize chat with system instructions\n",
        "            chat = self.client.chats.create(\n",
        "                model=\"gemini-2.0-flash\",\n",
        "                config=types.GenerateContentConfig(\n",
        "                    system_instruction=prompt\n",
        "                ),\n",
        "            )\n",
        "            # Send the user question to get response\n",
        "            resp = chat.send_message(user_question)\n",
        "            logger.info(\"Successfully generated report with Gemini\")\n",
        "            return resp.text\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error generating report: {e}\")\n",
        "            return f\"Error generating report: {str(e)}\"\n",
        "\n",
        "\n",
        "    def ask_agent(self, query: str, analysis_data: Dict = None) -> str:\n",
        "        \"\"\"\n",
        "        Generate a response using the AI agent for general genomics questions.\n",
        "\n",
        "        Uses the Gemini API to provide an informed response based on both general\n",
        "        knowledge and specific analysis results when available.\n",
        "\n",
        "        Args:\n",
        "            query (str): User's query text about genomics or variant analysis\n",
        "            analysis_data (Dict, optional): Current analysis data to incorporate into the response\n",
        "\n",
        "        Returns:\n",
        "            str: AI-generated response addressing the user's question\n",
        "        \"\"\"\n",
        "        # Extract reports from analysis data if available\n",
        "        input_data = analysis_data.get(\"reports\", {}) if analysis_data else {}\n",
        "\n",
        "        # Create a prompt that instructs the AI to provide both general knowledge and specific analysis\n",
        "        prompt = f\"\"\"\n",
        "            You are an AI agent, helping out a biologist. The user asked the following question: \"{query}\".\n",
        "            Based on the question, internet searches (especially on PubMed, ClinVar and other reputable genomics sources)\n",
        "            and the provided analysis results below, please generate a response.\n",
        "            Unless the user specifies they want you to base your reply only on the results,\n",
        "            make sure to always first answer the question generally (based on knowledge or internet search results),\n",
        "            and then more specifically based on the results provided below.\n",
        "\n",
        "            Analysis Results:\n",
        "            {input_data}\n",
        "        \"\"\"\n",
        "\n",
        "        # Initialize chat with system instructions\n",
        "        chat = self.client.chats.create(\n",
        "            model=\"gemini-2.0-flash\",\n",
        "            config=types.GenerateContentConfig(\n",
        "                system_instruction=prompt\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # Send user query and return the response\n",
        "        resp = chat.send_message(query)\n",
        "        return resp.text\n",
        "\n",
        "    def generate_comparison_report(self, query: str, reports: List[str], indices: List[int]) -> str:\n",
        "        \"\"\"\n",
        "        Generate a report comparing multiple variants.\n",
        "\n",
        "        Takes individual variant reports and produces a comparative analysis\n",
        "        addressing the user's specific question about the variants.\n",
        "\n",
        "        Args:\n",
        "            query (str): User's query about the variants comparison\n",
        "            reports (List[str]): List of individual variant reports to compare\n",
        "            indices (List[int]): Indices of the variants being compared\n",
        "\n",
        "        Returns:\n",
        "            str: Generated comparison report highlighting differences and similarities\n",
        "\n",
        "        Raises:\n",
        "            Exception: If there's an error generating the comparison report\n",
        "        \"\"\"\n",
        "        # Create a prompt that instructs the AI to compare variants\n",
        "        augmented_prompt = f\"\"\"\n",
        "        You are an AI agent, helping out a biologist. The user asked the following question: \"{query}\".\n",
        "        Here are the reports for two variants:\n",
        "\n",
        "        Report for Variant {indices[0]+1}:\n",
        "        {reports[0]}\n",
        "\n",
        "        Report for Variant {indices[1]+1}:\n",
        "        {reports[1]}\n",
        "\n",
        "        Based on these reports, please provide a comparison of the two variants,\n",
        "        addressing the user's question.\n",
        "        \"\"\"\n",
        "\n",
        "        try:\n",
        "            # Initialize chat with system instructions\n",
        "            chat = self.client.chats.create(\n",
        "                model=\"gemini-2.0-flash\",\n",
        "                config=types.GenerateContentConfig(\n",
        "                    system_instruction=augmented_prompt\n",
        "                )\n",
        "            )\n",
        "            # Send query and return response\n",
        "            resp = chat.send_message(query)\n",
        "            return resp.text\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error generating report: {e}\")\n",
        "            return f\"Error generating comparison report: {str(e)}\"\n",
        "\n",
        "print(\"\\n\", \"-\" * 75)\n",
        "print(\"\\n ðŸ’» ScientificTextGenerator Class was successfully defined ! (1/3)\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-21T02:56:29.263124Z",
          "iopub.execute_input": "2025-04-21T02:56:29.263397Z",
          "iopub.status.idle": "2025-04-21T02:56:29.280647Z",
          "shell.execute_reply.started": "2025-04-21T02:56:29.263374Z",
          "shell.execute_reply": "2025-04-21T02:56:29.279555Z"
        },
        "id": "IOwe35sdYYuG"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class VariantAnalysisPipeline:\n",
        "    \"\"\"\n",
        "    An end-to-end pipeline for analyzing genomic variants.\n",
        "\n",
        "    This pipeline handles the complete workflow of variant analysis:\n",
        "    - Extract variant information from VCF files\n",
        "    - Create altered genome sequences with variants\n",
        "    - Analyze genomic features using SegmentNT neural network\n",
        "    - Query ClinVar for clinical significance\n",
        "    - Generate scientific reports using AI\n",
        "\n",
        "    The pipeline maintains state between operations and allows for analysis\n",
        "    of multiple variants from the same VCF file.\n",
        "\n",
        "    Attributes:\n",
        "        vcf_file_path (str): Path to the VCF file containing variants\n",
        "        segment_nt_model (str): Model ID for the SegmentNT model to use\n",
        "        clinvar_api_key (str): API key for accessing ClinVar database\n",
        "        tokenizer: Tokenizer for the neural network model\n",
        "        model: Neural network model for genomic analysis\n",
        "        text_generator: ScientificTextGenerator instance for report generation\n",
        "        variants (list): List of extracted variants from VCF\n",
        "        current_variant_index (int): Index of the currently selected variant\n",
        "        current_analysis (dict): Dictionary containing analysis results for current variant\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, vcf_file_path: str, api_key: str,\n",
        "                 segment_nt_model: str = \"InstaDeepAI/segment_nt\",\n",
        "                 clinvar_api_key: Optional[str] = None):\n",
        "        \"\"\"\n",
        "        Initialize the Variant Analysis Pipeline.\n",
        "\n",
        "        Sets up the pipeline with necessary components and configuration for\n",
        "        analyzing genomic variants from VCF files.\n",
        "\n",
        "        Args:\n",
        "            vcf_file_path (str): Path to VCF file containing variants\n",
        "            api_key (str): Google API key for Gemini model access\n",
        "            segment_nt_model (str): Model ID for SegmentNT neural network\n",
        "            clinvar_api_key (str, optional): API key for ClinVar database\n",
        "        \"\"\"\n",
        "        self.vcf_file_path = vcf_file_path\n",
        "        self.api_key = api_key\n",
        "        self.segment_nt_model = segment_nt_model\n",
        "        self.clinvar_api_key = clinvar_api_key\n",
        "\n",
        "        # Initialize neural network components\n",
        "        self.tokenizer = None\n",
        "        self.model = None\n",
        "        # Initialize text generator for reports\n",
        "        self.text_generator = ScientificTextGenerator(api_key)\n",
        "\n",
        "        # Initialize data storage\n",
        "        self.variants = []\n",
        "        self.current_variant_index = 0\n",
        "        self.current_analysis = {}\n",
        "\n",
        "        logger.info(\"Variant Analysis Pipeline initialized\")\n",
        "\n",
        "    def load_model(self):\n",
        "        \"\"\"\n",
        "        Load the SegmentNT neural network model for genomic analysis.\n",
        "\n",
        "        Downloads and initializes the SegmentNT model and tokenizer from HuggingFace,\n",
        "        configuring it for genomic sequence analysis. Handles model configuration\n",
        "        for appropriate sequence lengths.\n",
        "\n",
        "        Returns:\n",
        "            self: The current instance for method chaining\n",
        "\n",
        "        Raises:\n",
        "            Exception: If there's an error downloading or loading the model\n",
        "        \"\"\"\n",
        "        logger.info(f\"Loading SegmentNT model: {self.segment_nt_model}\")\n",
        "        try:\n",
        "            # Set cache directory explicitly and force download\n",
        "            cache_dir = \"./model_cache\"\n",
        "            os.makedirs(cache_dir, exist_ok=True)\n",
        "\n",
        "            # Set HF_HUB_OFFLINE to 0 to ensure online mode\n",
        "            os.environ['HF_HUB_OFFLINE'] = '0'\n",
        "\n",
        "            print(f\"Attempting to download tokenizer from {self.segment_nt_model}\")\n",
        "            # Load tokenizer with appropriate configuration\n",
        "            self.tokenizer = AutoTokenizer.from_pretrained(\n",
        "                self.segment_nt_model,\n",
        "                trust_remote_code=True,\n",
        "                cache_dir=cache_dir,\n",
        "                local_files_only=False,\n",
        "                use_auth_token=False  # Set to your HF token if using private models\n",
        "            )\n",
        "\n",
        "            print(f\"Tokenizer loaded, now loading model from {self.segment_nt_model}\")\n",
        "            # Load neural network model\n",
        "            self.model = AutoModel.from_pretrained(\n",
        "                self.segment_nt_model,\n",
        "                trust_remote_code=True,\n",
        "                cache_dir=cache_dir,\n",
        "                local_files_only=False,\n",
        "                use_auth_token=False)\n",
        "\n",
        "            # Configure model for appropriate sequence length processing\n",
        "            max_num_dna_tokens = 1668\n",
        "            if max_num_dna_tokens + 1 > 5001:\n",
        "                # Calculate rescaling factor for rotary embeddings\n",
        "                inference_rescaling_factor = (max_num_dna_tokens + 1) / 2048\n",
        "                num_layers = len(self.model.esm.encoder.layer)\n",
        "                # Apply rescaling to each layer\n",
        "                for layer in range(num_layers):\n",
        "                   self.model.esm.encoder.layer[layer].attention.self.rotary_embeddings.rescaling_factor = inference_rescaling_factor\n",
        "\n",
        "            logger.info(\"Model loaded successfully\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error loading model: {e}\")\n",
        "            print(f\"Detailed error: {str(e)}\")\n",
        "            raise\n",
        "        return self\n",
        "\n",
        "\n",
        "    def extract_variants(self, max_variants: int = 10):\n",
        "        \"\"\"\n",
        "        Extract variant information from VCF file.\n",
        "\n",
        "        Parses VCF file and extracts essential information about genetic variants,\n",
        "        including position, reference/alternate alleles, and SPDI notation.\n",
        "        Limits extraction to the specified maximum number of variants.\n",
        "\n",
        "        Args:\n",
        "            max_variants (int): Maximum number of variants to extract from the VCF\n",
        "\n",
        "        Returns:\n",
        "            self: The current instance for method chaining\n",
        "\n",
        "        Raises:\n",
        "            Exception: If there's an error reading or parsing the VCF file\n",
        "        \"\"\"\n",
        "        logger.info(f\"Extracting variants from {self.vcf_file_path}\")\n",
        "        try:\n",
        "            # Open VCF file with pysam\n",
        "            vcf = pysam.VariantFile(self.vcf_file_path)  # auto-detects format\n",
        "\n",
        "            output_list = []\n",
        "            for rec in vcf:\n",
        "                # Extract the SPDI notation (Sequence Position Deletion Insertion)\n",
        "                spdi = rec.info.get('CLNHGVS')\n",
        "                if spdi:\n",
        "                    spdi = spdi[0]\n",
        "                    # Clean up SPDI notation if needed\n",
        "                    reformatted_spdi = spdi\n",
        "                    count = 0\n",
        "                    for letter in spdi[-3:]:\n",
        "                        if letter.islower():\n",
        "                            count += 1\n",
        "                    if count == 3:\n",
        "                        reformatted_spdi = spdi[:-3]\n",
        "                else:\n",
        "                    reformatted_spdi = None\n",
        "\n",
        "                # reformat the Alternate Allele:\n",
        "                alt_allele=rec.alts[0]\n",
        "                # remove parenthesis and quotation marks\n",
        "                reformatted_alt=alt_allele.strip(\"'\\\"\")\n",
        "\n",
        "                # Create variant record with essential information\n",
        "                output = {\n",
        "                    \"Type\": rec.info.get('MC'),\n",
        "                    \"Chromosome\": rec.contig,\n",
        "                    \"Position\": rec.pos,\n",
        "                    \"Reference Allele\": rec.ref,\n",
        "                    \"Alternate Allele\": reformatted_alt,\n",
        "                    \"Canonical SPDI\": reformatted_spdi\n",
        "                }\n",
        "\n",
        "                output_list.append(output)\n",
        "                # Stop if we've reached the maximum number of variants\n",
        "                if len(output_list) >= max_variants:\n",
        "                    break\n",
        "\n",
        "            vcf.close()\n",
        "            self.variants = output_list\n",
        "\n",
        "            # Set the first variant as current by default if any variants were found\n",
        "            if self.variants:\n",
        "                self.current_analysis[\"variant\"] = self.variants[0]\n",
        "                logger.info(f\"Set initial variant in current_analysis: {self.current_analysis['variant']}\")\n",
        "\n",
        "            logger.info(f\"Extracted {len(output_list)} variants\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error extracting variants: {e}\")\n",
        "            raise\n",
        "\n",
        "        return self\n",
        "\n",
        "    def prepare_altered_genome(self, variant_index: int):\n",
        "        \"\"\"\n",
        "        Prepare the altered genome by inserting the variant into the reference sequence.\n",
        "\n",
        "        Retrieves the reference genome sequence and creates an altered version\n",
        "        by inserting the variant at the appropriate position. This creates the\n",
        "        genome sequence that will be analyzed by SegmentNT.\n",
        "\n",
        "        Args:\n",
        "            variant_index (int): Index of the variant in the variants list to analyze\n",
        "\n",
        "        Returns:\n",
        "            self: The current instance for method chaining\n",
        "\n",
        "        Raises:\n",
        "            ValueError: If no variants have been extracted or index is invalid\n",
        "            FileNotFoundError: If reference genome file is not found\n",
        "            Exception: For other errors in sequence preparation\n",
        "        \"\"\"\n",
        "        # Validate that variants have been extracted\n",
        "        if not self.variants:\n",
        "            logger.error(\"No variants extracted. Call extract_variants() first.\")\n",
        "            return self\n",
        "\n",
        "        # Validate variant index\n",
        "        if variant_index >= len(self.variants):\n",
        "            logger.error(f\"Invalid variant index {variant_index}. Only {len(self.variants)} variants available.\")\n",
        "            return self\n",
        "\n",
        "        # Set current variant and extract information\n",
        "        self.current_variant_index = variant_index\n",
        "        variant = self.variants[variant_index]\n",
        "\n",
        "        logger.info(f\"Preparing altered genome for variant at position {variant['Position']}\")\n",
        "\n",
        "        # Extract variant details\n",
        "        chromosome = variant[\"Chromosome\"]\n",
        "        position = variant[\"Position\"]\n",
        "        ref_allele = variant[\"Reference Allele\"]\n",
        "        alt_allele = variant[\"Alternate Allele\"]\n",
        "        alt_allele_string = ''.join(str(x) for x in alt_allele)\n",
        "\n",
        "        # Access reference genome - handles both .fa and .fa.gz files\n",
        "        fasta_path = f\"/content/Homo_sapiens.GRCh38.dna.chromosome.{chromosome}.fa\"\n",
        "        if not os.path.exists(fasta_path):\n",
        "            fasta_path = f\"/content/Homo_sapiens.GRCh38.dna.chromosome.{chromosome}.fa.gz\"\n",
        "\n",
        "        try:\n",
        "            # Determine if file is gzipped\n",
        "            is_gzipped = fasta_path.endswith('.gz')\n",
        "\n",
        "            # Open file with appropriate method\n",
        "            opener = gzip.open if is_gzipped else open\n",
        "            mode = 'rt' if is_gzipped else 'r'\n",
        "\n",
        "            # Read reference genome sequence\n",
        "            with opener(fasta_path, mode) as handle:\n",
        "                record = next(SeqIO.parse(handle, \"fasta\"))\n",
        "                ref_sequence = str(record.seq)\n",
        "\n",
        "            # Alter the reference sequence by inserting variant\n",
        "            altered_seq = ref_sequence[:position-1] + alt_allele_string + ref_sequence[position:]\n",
        "\n",
        "            # Store in current analysis\n",
        "            self.current_analysis[\"altered_genome\"] = altered_seq\n",
        "            self.current_analysis[\"variant\"] = variant\n",
        "            self.current_analysis[\"position\"] = position\n",
        "\n",
        "            logger.info(\"Altered genome prepared successfully\")\n",
        "\n",
        "        except FileNotFoundError:\n",
        "            logger.error(f\"Reference genome file not found: {fasta_path}\")\n",
        "            raise\n",
        "        except (OSError, IOError) as e:\n",
        "            logger.error(f\"Error reading genome file: {e}\")\n",
        "            raise\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error preparing altered genome: {e}\")\n",
        "            raise\n",
        "\n",
        "        return self\n",
        "\n",
        "    def run_segment_nt(self, flank_size: int = 5000):\n",
        "        \"\"\"\n",
        "        Run SegmentNT neural network analysis on the altered genome.\n",
        "\n",
        "        Analyzes the genomic context around the variant to identify functional\n",
        "        elements and their probabilities. Processes a sequence window centered\n",
        "        on the variant position and calculates probabilities for various\n",
        "        genomic features.\n",
        "\n",
        "        Args:\n",
        "            flank_size (int): Size of the flanking region to analyze around the variant\n",
        "\n",
        "        Returns:\n",
        "            self: The current instance for method chaining\n",
        "\n",
        "        Raises:\n",
        "            ValueError: If altered genome not prepared or model not loaded\n",
        "            Exception: For errors during model inference or analysis\n",
        "        \"\"\"\n",
        "        # Validate that altered genome has been prepared\n",
        "        if \"altered_genome\" not in self.current_analysis:\n",
        "            logger.error(\"Altered genome not prepared. Call prepare_altered_genome() first.\")\n",
        "            return self\n",
        "\n",
        "        # Validate that model has been loaded\n",
        "        if self.model is None or self.tokenizer is None:\n",
        "            logger.error(\"SegmentNT model not loaded. Call load_model() first.\")\n",
        "            return self\n",
        "\n",
        "        logger.info(\"Running SegmentNT analysis\")\n",
        "\n",
        "        try:\n",
        "            # Get altered sequence and variant position\n",
        "            altered_seq = self.current_analysis[\"altered_genome\"]\n",
        "            position = self.current_analysis[\"position\"]\n",
        "\n",
        "            # Calculate start and end indices for the sequence window\n",
        "            max_num_dna_tokens = 1668\n",
        "            idx_start = position - 1 - flank_size\n",
        "            idx_stop = idx_start + max_num_dna_tokens * 6\n",
        "\n",
        "            # Ensure indices are valid\n",
        "            if idx_start < 0:\n",
        "                idx_start = 0\n",
        "            if idx_stop > len(altered_seq):\n",
        "                idx_stop = len(altered_seq)\n",
        "\n",
        "            # Extract sequence window and tokenize for model input\n",
        "            sequences = [altered_seq[idx_start:idx_stop]]\n",
        "            tokens = self.tokenizer.batch_encode_plus(\n",
        "                sequences,\n",
        "                return_tensors=\"pt\",\n",
        "                padding=\"max_length\",\n",
        "                max_length=max_num_dna_tokens\n",
        "            )[\"input_ids\"]\n",
        "\n",
        "            # Run inference on GPU if available, otherwise CPU\n",
        "            device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "            attention_mask = (tokens != self.tokenizer.pad_token_id)\n",
        "\n",
        "            # Perform model inference\n",
        "            with torch.no_grad():\n",
        "                outputs = self.model(\n",
        "                    tokens,\n",
        "                    attention_mask=attention_mask,\n",
        "                )\n",
        "\n",
        "            # Process model outputs\n",
        "            logits = outputs[\"logits\"]\n",
        "            probabilities = np.asarray(torch.nn.functional.softmax(logits, dim=-1).cpu())[...,-1]\n",
        "\n",
        "            # Get feature list from model config\n",
        "            features = self.model.config.features\n",
        "\n",
        "            # Analyze probabilities at variant position\n",
        "            index_of_position = position - (position - 1 - flank_size)\n",
        "            if 0 <= index_of_position < probabilities.shape[1]:\n",
        "                probabilities_at_position = probabilities[0][index_of_position]\n",
        "\n",
        "                # Print probabilities for variant position\n",
        "                logger.info(f\"Probabilities at position {position}:\")\n",
        "\n",
        "                # Extract classes with probabilities\n",
        "                class_probabilities = {}\n",
        "                for i, feature in enumerate(features):\n",
        "                    prob = probabilities_at_position[i]\n",
        "                    logger.info(f\"  {feature}: {prob:.4f}\")\n",
        "                    class_probabilities[feature] = float(prob)  # Convert to float for JSON serialization\n",
        "\n",
        "                # Extract significant genomic classes (probability > 0.8)\n",
        "                genomic_classes_with_prob = {}\n",
        "                for class_name, probability in class_probabilities.items():\n",
        "                    if probability > 0.8:\n",
        "                        genomic_classes_with_prob[class_name] = probability\n",
        "\n",
        "                # Compute length of analyzed genome sequence\n",
        "                seq_length = probabilities.shape[-2]\n",
        "\n",
        "                # Store results in current analysis\n",
        "                self.current_analysis[\"sequence_length\"] = seq_length\n",
        "                self.current_analysis[\"probabilities_all_segNT\"] = probabilities[0]\n",
        "                self.current_analysis[\"features_all_segNT\"] = features\n",
        "                self.current_analysis[\"likely_genomic_classes_with_prob\"] = genomic_classes_with_prob\n",
        "\n",
        "                logger.info(f\"Identified genomic classes with probabilities: {genomic_classes_with_prob}\")\n",
        "\n",
        "            else:\n",
        "                logger.warning(f\"Position index {index_of_position} out of range for probabilities array\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error running SegmentNT analysis: {e}\")\n",
        "            raise\n",
        "\n",
        "        return self\n",
        "\n",
        "    def query_clinvar(self):\n",
        "        \"\"\"\n",
        "        Query ClinVar API for clinical significance information about the variant.\n",
        "\n",
        "        Retrieves pathogenicity, allelic frequency, protein change, and gene information\n",
        "        from NCBI's ClinVar database using the variant's SPDI notation as identifier.\n",
        "\n",
        "        Returns:\n",
        "            self: The current instance for method chaining\n",
        "\n",
        "        Raises:\n",
        "            ValueError: If no variant has been selected\n",
        "            RequestException: For API request failures\n",
        "            Exception: For other errors during ClinVar querying\n",
        "        \"\"\"\n",
        "        # Validate that a variant has been selected\n",
        "        if \"variant\" not in self.current_analysis:\n",
        "            logger.error(\"No variant selected. Call prepare_altered_genome() first.\")\n",
        "            return self\n",
        "\n",
        "        # Get variant and SPDI notation\n",
        "        variant = self.current_analysis[\"variant\"]\n",
        "        spdi = variant.get('Canonical SPDI')\n",
        "\n",
        "        # Check if SPDI notation is available\n",
        "        if not spdi:\n",
        "            logger.warning(\"No SPDI notation available for this variant. Skipping ClinVar query.\")\n",
        "            self.current_analysis[\"clinvar_data\"] = {\n",
        "                \"pathogenicity\": None,\n",
        "                \"allelic_freq\": None,\n",
        "                \"protein_change\": None,\n",
        "                \"gene_name\": None\n",
        "            }\n",
        "            return self\n",
        "\n",
        "        logger.info(f\"Querying ClinVar for variant: {spdi}\")\n",
        "\n",
        "        # Check API key availability\n",
        "        if not self.clinvar_api_key:\n",
        "            logger.warning(\"No ClinVar API key provided. Using unauthenticated requests.\")\n",
        "\n",
        "        try:\n",
        "            # Construct API query to search for variant\n",
        "            base_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi\"\n",
        "            params = {\n",
        "                \"db\": \"clinvar\",\n",
        "                \"term\": f\"{spdi}\",\n",
        "                \"retmode\": \"json\",\n",
        "                \"retmax\": 3\n",
        "            }\n",
        "\n",
        "            # Add API key if available\n",
        "            if self.clinvar_api_key:\n",
        "              params[\"api_key\"] = self.clinvar_api_key\n",
        "\n",
        "            # Send search request\n",
        "            response = requests.get(base_url, params=params)\n",
        "            response.raise_for_status()\n",
        "            results = response.json()\n",
        "\n",
        "            # Check if we got any results\n",
        "            if (\"esearchresult\" not in results or\n",
        "                \"idlist\" not in results[\"esearchresult\"] or\n",
        "                not results[\"esearchresult\"][\"idlist\"]):\n",
        "                logger.warning(f\"No ClinVar records found for variant: {spdi}\")\n",
        "                self.current_analysis[\"clinvar_data\"] = {\n",
        "                    \"pathogenicity\": None,\n",
        "                    \"allelic_freq\": None,\n",
        "                    \"protein_change\": None,\n",
        "                    \"gene_name\": None\n",
        "                }\n",
        "                return self\n",
        "\n",
        "            # Get the first ID from the list of results\n",
        "            variant_id = results[\"esearchresult\"][\"idlist\"][0]\n",
        "\n",
        "            # Get detailed information using the variant ID\n",
        "            esummary_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esummary.fcgi\"\n",
        "            esummary_params = {\n",
        "                \"db\": \"clinvar\",\n",
        "                \"id\": variant_id,\n",
        "                \"retmode\": \"json\"\n",
        "           }\n",
        "\n",
        "            # Add API key if available\n",
        "            if self.clinvar_api_key:\n",
        "                esummary_params[\"api_key\"] = self.clinvar_api_key\n",
        "\n",
        "            # Send summary request\n",
        "            esummary_response = requests.get(esummary_url, params=esummary_params)\n",
        "            esummary_response.raise_for_status()\n",
        "            esummary_results = esummary_response.json()\n",
        "\n",
        "            # Extract relevant clinical information\n",
        "            result_data = esummary_results['result'][variant_id]\n",
        "            pathogenicity = result_data.get('germline_classification', {}).get('description')\n",
        "            allelic_freq = result_data.get('allele_freq_set')\n",
        "            protein_change = result_data.get('protein_change')\n",
        "            gene_name = result_data.get('gene_sort')\n",
        "\n",
        "            # Store ClinVar data in current analysis\n",
        "            self.current_analysis[\"clinvar_data\"] = {\n",
        "                \"pathogenicity\": pathogenicity,\n",
        "                \"allelic_freq\": allelic_freq,\n",
        "                \"protein_change\": protein_change,\n",
        "                \"gene_name\": gene_name\n",
        "            }\n",
        "\n",
        "            logger.info(f\"ClinVar data retrieved: {pathogenicity}, {gene_name}\")\n",
        "\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            # Handle API request errors\n",
        "            logger.error(f\"ClinVar API request failed: {e}\")\n",
        "            self.current_analysis[\"clinvar_data\"] = {\n",
        "                \"error\": str(e),\n",
        "                \"pathogenicity\": None,\n",
        "                \"allelic_freq\": None,\n",
        "                \"protein_change\": None,\n",
        "                \"gene_name\": None\n",
        "            }\n",
        "        except KeyError as e:\n",
        "            # Handle response parsing errors\n",
        "            logger.error(f\"Error parsing ClinVar response: {e}\")\n",
        "            self.current_analysis[\"clinvar_data\"] = {\n",
        "                \"error\": f\"Error parsing response: {str(e)}\",\n",
        "                \"pathogenicity\": None,\n",
        "                \"allelic_freq\": None,\n",
        "                \"protein_change\": None,\n",
        "                \"gene_name\": None\n",
        "            }\n",
        "        except Exception as e:\n",
        "            # Handle unexpected errors\n",
        "            logger.error(f\"Unexpected error querying ClinVar: {e}\")\n",
        "            self.current_analysis[\"clinvar_data\"] = {\n",
        "                \"error\": f\"Unexpected error: {str(e)}\",\n",
        "                \"pathogenicity\": None,\n",
        "                \"allelic_freq\": None,\n",
        "                \"protein_change\": None,\n",
        "                \"gene_name\": None\n",
        "            }\n",
        "\n",
        "        return self\n",
        "\n",
        "    def generate_reports(self, user_question: str, output_dir: Optional[str] = None):\n",
        "        \"\"\"\n",
        "        Generate scientific reports for the variant using AI text generation.\n",
        "\n",
        "        Creates a comprehensive scientific report based on all collected\n",
        "        analysis data, addressing the user's specific question about the variant.\n",
        "        Can optionally save the report to a file.\n",
        "\n",
        "        Args:\n",
        "            user_question (str): Question from the user about the variant\n",
        "            output_dir (str, optional): Directory to save the reports to\n",
        "\n",
        "        Returns:\n",
        "            str: The generated report text\n",
        "\n",
        "        Raises:\n",
        "            ValueError: If no variant has been selected for analysis\n",
        "            Exception: For errors during report generation\n",
        "        \"\"\"\n",
        "        # Validate that a variant has been selected\n",
        "        if \"variant\" not in self.current_analysis:\n",
        "            logger.error(\"No variant selected. Pipeline must be run first.\")\n",
        "            return \"Error: No variant selected. Please run the analysis pipeline first.\"\n",
        "\n",
        "        try:\n",
        "            # Gather all analysis data\n",
        "            variant_data = self.current_analysis[\"variant\"] # Data extracted from uploaded VCF file\n",
        "            genomic_classes_with_prob = self.current_analysis.get(\"likely_genomic_classes_with_prob\", {}) #Outputs of SegmentNT model\n",
        "            clinvar_data = self.current_analysis.get(\"clinvar_data\", {}) #Data queried from ClinVar database\n",
        "\n",
        "            # Extract ClinVar data\n",
        "            protein_change = clinvar_data.get(\"protein_change\")\n",
        "            gene_name = clinvar_data.get(\"gene_name\")\n",
        "\n",
        "            logger.info(f\"Generating reports for variant at position {variant_data['Position']}\")\n",
        "\n",
        "            # Generate report using text generator\n",
        "            response = self.text_generator.generate_report(\n",
        "                variant_data, clinvar_data, genomic_classes_with_prob, protein_change,\n",
        "                gene_name, user_question)\n",
        "\n",
        "            # Store report in current analysis\n",
        "            self.current_analysis[\"reports\"] = {\n",
        "             \"response\": response\n",
        "            }\n",
        "\n",
        "            # Save report to file if output directory is provided\n",
        "            if output_dir:\n",
        "                os.makedirs(output_dir, exist_ok=True)\n",
        "                # Create a filename based on variant ID\n",
        "                variant_id = str(variant_data.get(\"Canonical SPDI\", \"variant\")).replace(\":\", \"_\")\n",
        "                response_path = os.path.join(output_dir, f\"report_{variant_id}.txt\")\n",
        "\n",
        "                # Write report to file\n",
        "                with open(response_path, \"w\") as f:\n",
        "                    f.write(response)\n",
        "\n",
        "                logger.info(f\"Reports saved to {output_dir}\")\n",
        "\n",
        "            return response\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error generating reports: {e}\")\n",
        "            return f\"Error generating reports: {str(e)}\"\n",
        "\n",
        "print(\"\\n\", \"-\" * 75)\n",
        "print(\"\\n ðŸ’» VariantAnalysisPipeline Class was successfully defined ! (2/3)\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-21T02:56:30.01757Z",
          "iopub.execute_input": "2025-04-21T02:56:30.017908Z",
          "iopub.status.idle": "2025-04-21T02:56:30.060246Z",
          "shell.execute_reply.started": "2025-04-21T02:56:30.017884Z",
          "shell.execute_reply": "2025-04-21T02:56:30.05922Z"
        },
        "jupyter": {
          "source_hidden": true
        },
        "id": "5bRC5s37YYuH"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class VariantAnalysisUI:\n",
        "    \"\"\"\n",
        "    User interface for the Variant Analysis Pipeline.\n",
        "\n",
        "    This class provides a complete UI for genomic variant analysis, featuring:\n",
        "    - VCF file upload functionality\n",
        "    - Google API integration for genomic queries\n",
        "    - Variant information display\n",
        "    - Interactive chat interface for querying variant data\n",
        "    - Report generation and download capabilities\n",
        "\n",
        "    The UI is designed for biologists and researchers working with genomic variants\n",
        "    and provides intuitive access to complex analysis functions.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Initialize the UI components and state.\n",
        "\n",
        "        Sets up all UI elements, defines styling, and prepares event handlers.\n",
        "        The UI starts in a disabled state until a VCF file is uploaded and processed.\n",
        "        \"\"\"\n",
        "        # Core state variables\n",
        "        self.pipeline = None\n",
        "        self.chat_history = []\n",
        "        self.output_dir = \"/content/output\"\n",
        "        os.makedirs(self.output_dir, exist_ok=True)\n",
        "\n",
        "        # Create styling for UI components\n",
        "        self.style = self._create_ui_styles()\n",
        "\n",
        "        # Define download button for chat history\n",
        "        self.download_chat_button = widgets.Button(\n",
        "            description='Download Chat History',\n",
        "            disabled=False,\n",
        "            icon='download'\n",
        "        )\n",
        "\n",
        "        # Set up UI components, event handlers, and chat display\n",
        "        self._create_ui_components()\n",
        "        self._setup_event_handlers()\n",
        "        self._initialize_chat_display()\n",
        "\n",
        "    def _create_ui_styles(self):\n",
        "        \"\"\"\n",
        "        Create and return CSS styles for UI components.\n",
        "\n",
        "        Defines the complete styling for the application including colors, fonts,\n",
        "        layout, and responsive design elements for all UI components.\n",
        "\n",
        "        Returns:\n",
        "            str: HTML/CSS styling for the UI components\n",
        "        \"\"\"\n",
        "        return \"\"\"\n",
        "        <style>\n",
        "        /* Main container and overall styling */\n",
        "        .genomic-app {\n",
        "            font-family: 'Roboto', sans-serif;\n",
        "            max-width: 1200px;\n",
        "            margin: 0 auto;\n",
        "            background-color: #f8fafb;\n",
        "            padding: 20px;\n",
        "            border-radius: 8px;\n",
        "            box-shadow: 0 2px 10px rgba(0,0,0,0.05);\n",
        "        }\n",
        "\n",
        "        /* Header styling */\n",
        "        .app-header {\n",
        "            background: linear-gradient(135deg, #4285F4, #34A853);\n",
        "            color: white;\n",
        "            padding: 15px 20px;\n",
        "            border-radius: 8px 8px 0 0;\n",
        "            margin-bottom: 20px;\n",
        "            text-align: center;\n",
        "        }\n",
        "\n",
        "        .app-header h1 {\n",
        "            margin: 0;\n",
        "            font-size: 28px;\n",
        "            font-weight: 500;\n",
        "        }\n",
        "\n",
        "        .app-header p {\n",
        "            margin: 5px 0 0;\n",
        "            opacity: 0.9;\n",
        "            font-size: 16px;\n",
        "        }\n",
        "\n",
        "        /* Section styling */\n",
        "        .section {\n",
        "            background-color: white;\n",
        "            border-radius: 6px;\n",
        "            box-shadow: 0 1px 3px rgba(0,0,0,0.1);\n",
        "            padding: 15px;\n",
        "            margin-bottom: 20px;\n",
        "        }\n",
        "\n",
        "        .section-header {\n",
        "            font-size: 18px;\n",
        "            font-weight: 500;\n",
        "            color: #4285F4;\n",
        "            border-bottom: 2px solid #e0e0e0;\n",
        "            padding-bottom: 8px;\n",
        "            margin-bottom: 15px;\n",
        "        }\n",
        "\n",
        "        /* Chat container */\n",
        "        .chat-container {\n",
        "            max-height: 400px;\n",
        "            overflow-y: auto;\n",
        "            border: 1px solid #e0e0e0;\n",
        "            padding: 10px;\n",
        "            margin-bottom: 15px;\n",
        "            background-color: #f9f9f9;\n",
        "            border-radius: 8px;\n",
        "            box-shadow: inset 0 1px 3px rgba(0,0,0,0.05);\n",
        "        }\n",
        "\n",
        "        .user-message {\n",
        "            background-color: #E3F2FD;\n",
        "            padding: 12px;\n",
        "            border-radius: 18px 18px 3px 18px;\n",
        "            margin-bottom: 12px;\n",
        "            max-width: 80%;\n",
        "            margin-left: auto;\n",
        "            word-wrap: break-word;\n",
        "            color: #37474F;\n",
        "            box-shadow: 0 1px 0.5px rgba(0,0,0,0.1);\n",
        "        }\n",
        "\n",
        "        .bot-message {\n",
        "            background-color: #FFFFFF;\n",
        "            padding: 12px;\n",
        "            border-radius: 18px 18px 18px 3px;\n",
        "            margin-bottom: 12px;\n",
        "            max-width: 80%;\n",
        "            border-left: 4px solid #4285F4;\n",
        "            word-wrap: break-word;\n",
        "            color: #212121;\n",
        "            box-shadow: 0 1px 0.5px rgba(0,0,0,0.1);\n",
        "        }\n",
        "\n",
        "        /* VCF info display */\n",
        "        .vcf-info {\n",
        "            background-color: #F5F7FF;\n",
        "            padding: 15px;\n",
        "            border-radius: 6px;\n",
        "            margin-top: 10px;\n",
        "            margin-bottom: 10px;\n",
        "            border-left: 4px solid #7986CB;\n",
        "        }\n",
        "\n",
        "        .variant-card {\n",
        "            background-color: white;\n",
        "            border-radius: 6px;\n",
        "            padding: 12px;\n",
        "            margin-bottom: 10px;\n",
        "            box-shadow: 0 1px 2px rgba(0,0,0,0.1);\n",
        "            transition: all 0.2s ease;\n",
        "        }\n",
        "\n",
        "        .variant-card:hover {\n",
        "            box-shadow: 0 3px 8px rgba(0,0,0,0.15);\n",
        "        }\n",
        "\n",
        "        /* Titles and text */\n",
        "        .title {\n",
        "            font-size: 22px;\n",
        "            font-weight: bold;\n",
        "            margin-bottom: 12px;\n",
        "            color: #4285F4;\n",
        "        }\n",
        "\n",
        "        .subtitle {\n",
        "            font-size: 16px;\n",
        "            font-weight: 500;\n",
        "            margin-top: 15px;\n",
        "            margin-bottom: 8px;\n",
        "            color: #5F6368;\n",
        "            border-bottom: 1px solid #e0e0e0;\n",
        "            padding-bottom: 5px;\n",
        "        }\n",
        "\n",
        "        /* Status indicators */\n",
        "        .loading {\n",
        "            color: #5F6368;\n",
        "            margin-top: 10px;\n",
        "            display: flex;\n",
        "            align-items: center;\n",
        "        }\n",
        "\n",
        "        .loading:before {\n",
        "            content: '';\n",
        "            display: inline-block;\n",
        "            width: 16px;\n",
        "            height: 16px;\n",
        "            margin-right: 8px;\n",
        "            border: 2px solid #4285F4;\n",
        "            border-radius: 50%;\n",
        "            border-top-color: transparent;\n",
        "            animation: spin 1s linear infinite;\n",
        "        }\n",
        "\n",
        "        @keyframes spin {\n",
        "            to { transform: rotate(360deg); }\n",
        "        }\n",
        "\n",
        "        /* Button styling */\n",
        "        .button-primary {\n",
        "            background-color: #4285F4;\n",
        "            color: white;\n",
        "            border: none;\n",
        "            padding: 10px 16px;\n",
        "            border-radius: 4px;\n",
        "            cursor: pointer;\n",
        "            font-weight: 500;\n",
        "            transition: background-color 0.2s;\n",
        "        }\n",
        "\n",
        "        .button-primary:hover {\n",
        "            background-color: #3367D6;\n",
        "        }\n",
        "\n",
        "        .button-secondary {\n",
        "            background-color: #5F6368;\n",
        "            color: white;\n",
        "            border: none;\n",
        "            padding: 10px 16px;\n",
        "            border-radius: 4px;\n",
        "            cursor: pointer;\n",
        "            font-weight: 500;\n",
        "            transition: background-color 0.2s;\n",
        "        }\n",
        "\n",
        "        .button-secondary:hover {\n",
        "            background-color: #494C50;\n",
        "        }\n",
        "\n",
        "        /* Input fields */\n",
        "        .input-field {\n",
        "            border: 1px solid #dadce0;\n",
        "            border-radius: 4px;\n",
        "            padding: 10px 12px;\n",
        "            font-size: 14px;\n",
        "            width: 100%;\n",
        "            transition: border 0.2s;\n",
        "        }\n",
        "\n",
        "        .input-field:focus {\n",
        "            border-color: #4285F4;\n",
        "            outline: none;\n",
        "        }\n",
        "\n",
        "        /* Pathogenicity indicators */\n",
        "        .pathogenic {\n",
        "            color: #D32F2F;\n",
        "            font-weight: 500;\n",
        "        }\n",
        "\n",
        "        .benign {\n",
        "            color: #388E3C;\n",
        "            font-weight: 500;\n",
        "        }\n",
        "\n",
        "        .uncertain {\n",
        "            color: #FFA000;\n",
        "            font-weight: 500;\n",
        "        }\n",
        "\n",
        "        /* Genomic class labels */\n",
        "        .genomic-class {\n",
        "            display: inline-block;\n",
        "            padding: 3px 8px;\n",
        "            border-radius: 12px;\n",
        "            margin-right: 5px;\n",
        "            margin-bottom: 5px;\n",
        "            font-size: 12px;\n",
        "            font-weight: 500;\n",
        "            background-color: #E8F0FE;\n",
        "            color: #185ABC;\n",
        "        }\n",
        "        </style>\n",
        "        \"\"\"\n",
        "    def _create_ui_components(self):\n",
        "        \"\"\"\n",
        "        Create and configure all UI widgets.\n",
        "\n",
        "        Initializes all UI components including:\n",
        "        - File upload widget\n",
        "        - Status and output displays\n",
        "        - Query input field\n",
        "        - Action buttons\n",
        "        - API key input field\n",
        "        - ClinVar API key input field\n",
        "\n",
        "        Each component is configured with appropriate properties and layout settings.\n",
        "        \"\"\"\n",
        "        # File upload component\n",
        "        self.file_upload = widgets.FileUpload(\n",
        "            description='Upload VCF file:',\n",
        "            accept='.vcf, .vcf.gz',\n",
        "            multiple=False\n",
        "        )\n",
        "\n",
        "        # Status and output components\n",
        "        self.status_output = widgets.Output()\n",
        "        self.vcf_info_output = widgets.Output()\n",
        "        self.chat_output = widgets.Output()\n",
        "        self.print_output = widgets.Output()\n",
        "\n",
        "        # Input components\n",
        "        self.query_input = widgets.Text(\n",
        "            placeholder='Ask a question about the uploaded variant data...',\n",
        "            description='Query:',\n",
        "            disabled=False,\n",
        "            layout=widgets.Layout(width='80%')\n",
        "        )\n",
        "\n",
        "        # Action buttons\n",
        "        self.send_button = widgets.Button(\n",
        "            description='Send',\n",
        "            disabled=False,\n",
        "            button_style='primary',\n",
        "            tooltip=\"Send your query\",\n",
        "            icon='paper-plane'\n",
        "        )\n",
        "\n",
        "        self.clear_chat_button = widgets.Button(\n",
        "            description='Clear Chat',\n",
        "            disabled=False,\n",
        "            button_style='danger',\n",
        "            tooltip=\"Clear the chat history\",\n",
        "            icon='trash'\n",
        "        )\n",
        "\n",
        "        # API key input and button\n",
        "        self.api_key_input = widgets.Text(\n",
        "            placeholder='Enter your Google API key',\n",
        "            description='API Key:',\n",
        "            layout=widgets.Layout(width='50%')\n",
        "        )\n",
        "\n",
        "        self.apply_api_key_button = widgets.Button(\n",
        "            description='Apply API Key(s)',\n",
        "            button_style='primary',\n",
        "            icon='check'\n",
        "        )\n",
        "\n",
        "        # ClinVar API key input (optional)\n",
        "        self.clinvar_key_input = widgets.Text(\n",
        "            placeholder='Enter your ClinVar API key (optional)',\n",
        "            description='ClinVar Key:',\n",
        "            layout=widgets.Layout(width='50%')\n",
        "        )\n",
        "\n",
        "\n",
        "    def _setup_event_handlers(self):\n",
        "        \"\"\"\n",
        "        Set up event handlers for UI components.\n",
        "\n",
        "        Connects UI components to their respective handler methods:\n",
        "        - File upload widget to on_file_upload_change\n",
        "        - Send button to on_send_button_click\n",
        "        - Clear chat button to on_clear_chat_button_click\n",
        "        - Apply API key button to on_apply_api_key_button_click\n",
        "        - Download chat button to on_download_chat_button_click\n",
        "\n",
        "        This establishes the interactive behavior of the UI.\n",
        "        \"\"\"\n",
        "        self.file_upload.observe(self.on_file_upload_change, names='value')\n",
        "        self.send_button.on_click(self.on_send_button_click)\n",
        "        self.clear_chat_button.on_click(self.on_clear_chat_button_click)\n",
        "        self.apply_api_key_button.on_click(self.on_apply_api_key_button_click)\n",
        "        self.download_chat_button.on_click(self.on_download_chat_button_click)\n",
        "\n",
        "    def _initialize_chat_display(self):\n",
        "        \"\"\"\n",
        "        Initialize the chat display widget.\n",
        "\n",
        "        Creates an empty chat container with appropriate styling.\n",
        "        This prepares the UI for user interaction with the chat interface.\n",
        "        \"\"\"\n",
        "        with self.chat_output:\n",
        "            clear_output()\n",
        "            display(HTML(self.style + \"<div class='chat-container' id='chat-container'></div>\"))\n",
        "\n",
        "    def on_file_upload_change(self, change):\n",
        "        \"\"\"\n",
        "        Handle file upload events.\n",
        "\n",
        "        Processes the uploaded VCF file and initializes the analysis pipeline.\n",
        "        Validates that an API key has been provided before processing the file.\n",
        "        Saves the uploaded file to a temporary location, initializes the\n",
        "        pipeline, extracts variants, and displays variant information.\n",
        "\n",
        "        Args:\n",
        "            change (dict): Change event data containing the uploaded file information\n",
        "        \"\"\"\n",
        "        if change['type'] == 'change' and change['name'] == 'value' and change['new']:\n",
        "            # Check if API key is provided\n",
        "            api_key = self.api_key_input.value.strip()\n",
        "            if not api_key:\n",
        "                with self.print_output:\n",
        "                    clear_output()\n",
        "                    print(\"Please enter your Google API key and click 'Apply API Key' before uploading a file.\")\n",
        "                    return\n",
        "\n",
        "            try:\n",
        "                # Get the uploaded file data\n",
        "                uploaded_files = change['new']\n",
        "                if not uploaded_files:\n",
        "                    return\n",
        "\n",
        "                # Get the first file\n",
        "                file_name = next(iter(uploaded_files))  # Get the filename\n",
        "                file_content = uploaded_files[file_name]['content']  # Get the content\n",
        "\n",
        "                # Create directory and save file\n",
        "                upload_dir = \"/content/uploads\"\n",
        "                os.makedirs(upload_dir, exist_ok=True)\n",
        "                file_path = os.path.join(upload_dir, file_name)\n",
        "\n",
        "                # Write the file content\n",
        "                with open(file_path, 'wb') as f:\n",
        "                    f.write(file_content)\n",
        "\n",
        "                with self.print_output:\n",
        "                    clear_output()\n",
        "                    print(f\"File uploaded: {file_name}\")\n",
        "                    print(\"Initializing pipeline and extracting variants...\")\n",
        "\n",
        "                # Initialize the pipeline\n",
        "                try:\n",
        "                    self.pipeline = self._initialize_pipeline(file_path, api_key)\n",
        "\n",
        "                    if self.pipeline is None:\n",
        "                        return\n",
        "\n",
        "                    # Extract variants\n",
        "                    self.pipeline.extract_variants()\n",
        "\n",
        "                    # Display variant information\n",
        "                    if self.pipeline.variants:\n",
        "                        self._display_variant_info()\n",
        "\n",
        "                        # Enable the query components\n",
        "                        self.query_input.disabled = False\n",
        "                        self.send_button.disabled = False\n",
        "                        self.clear_chat_button.disabled = False\n",
        "\n",
        "                        # Add a welcome message to the chat\n",
        "                        self.add_message_to_chat(\n",
        "                            \"Welcome! I've analyzed your VCF file. You can now ask questions about the variants.\",\n",
        "                            is_user=False\n",
        "                        )\n",
        "                    else:\n",
        "                        with self.print_output:\n",
        "                            clear_output()\n",
        "                            print(\"No variants found in the uploaded file.\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    with self.print_output:\n",
        "                        clear_output()\n",
        "                        print(f\"Error processing file: {str(e)}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                with self.print_output:\n",
        "                    clear_output()\n",
        "                    print(f\"Error handling file upload: {str(e)}\")\n",
        "                    print(\"Please make sure you're uploading a valid VCF file.\")\n",
        "\n",
        "    def on_apply_api_key_button_click(self, b):\n",
        "        \"\"\"\n",
        "        Handle apply API key button click events.\n",
        "\n",
        "        Validates and applies the provided Google API key.\n",
        "        Displays a success message or error message based on input validation.\n",
        "\n",
        "        Args:\n",
        "            b (Button): Button widget that triggered the event\n",
        "        \"\"\"\n",
        "        api_key = self.api_key_input.value.strip()\n",
        "\n",
        "        with self.print_output:\n",
        "            clear_output()\n",
        "            try:\n",
        "                # Test API key validity\n",
        "                genai.configure(api_key=api_key)\n",
        "                model = genai.GenerativeModel('gemini-pro')\n",
        "                response = model.generate_content(\"Test\")\n",
        "                print(\"âœ… API Key validated successfully!\")\n",
        "                print(\"You can now upload your VCF file.\")\n",
        "            except Exception as e:\n",
        "                print(\"âŒ Invalid API key. Please check your credentials.\")\n",
        "                print(f\"Error: {str(e)}\")\n",
        "                return\n",
        "\n",
        "    def _initialize_pipeline(self, vcf_file_path, api_key=None):\n",
        "        \"\"\"\n",
        "        Initialize the variant analysis pipeline with the uploaded file.\n",
        "\n",
        "        Creates an instance of VariantAnalysisPipeline with the provided\n",
        "        VCF file path and API key. Optionally includes ClinVar API key\n",
        "        if provided.\n",
        "\n",
        "        Args:\n",
        "            vcf_file_path (str): Path to the uploaded VCF file\n",
        "            api_key (str, optional): Google API key for accessing services\n",
        "\n",
        "        Returns:\n",
        "            VariantAnalysisPipeline: Initialized pipeline object or None if error occurs\n",
        "        \"\"\"\n",
        "        if not api_key:\n",
        "            with self.print_output:\n",
        "                clear_output()\n",
        "                print(\"Please enter your Google API key.\")\n",
        "            return None\n",
        "\n",
        "        try:\n",
        "            # Get ClinVar API key if provided\n",
        "            clinvar_key = self.clinvar_key_input.value.strip() or None\n",
        "\n",
        "            pipeline = VariantAnalysisPipeline(\n",
        "                vcf_file_path=vcf_file_path,\n",
        "                api_key=api_key,\n",
        "                clinvar_api_key=clinvar_key\n",
        "            )\n",
        "            return pipeline\n",
        "        except Exception as e:\n",
        "            with self.print_output:\n",
        "                clear_output()\n",
        "                print(f\"Error initializing pipeline: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def _display_variant_info(self):\n",
        "        \"\"\"\n",
        "        Display variant information in the UI.\n",
        "\n",
        "        Creates a formatted HTML display of all identified variants.\n",
        "        Clears any previous variant information and shows the new data\n",
        "        in a structured, user-friendly format.\n",
        "        \"\"\"\n",
        "        with self.vcf_info_output:\n",
        "            clear_output()\n",
        "            display(HTML(self.style))\n",
        "            variant_html = \"<div class='vcf-info'>\"\n",
        "            variant_html += \"<div class='title'>Variant Information</div>\"\n",
        "\n",
        "            for i, variant in enumerate(self.pipeline.variants):\n",
        "                variant_html += f\"<div class='subtitle'>Variant {i+1}</div>\"\n",
        "                variant_html += \"<ul>\"\n",
        "                for key, value in variant.items():\n",
        "                    variant_html += f\"<li><strong>{key}:</strong> {value}</li>\"\n",
        "                variant_html += \"</ul>\"\n",
        "\n",
        "            variant_html += \"</div>\"\n",
        "            display(HTML(variant_html))\n",
        "\n",
        "    def on_send_button_click(self, b):\n",
        "        \"\"\"\n",
        "        Handle send button click events.\n",
        "\n",
        "        Processes the user's query and generates appropriate responses.\n",
        "        Detects the intent of the query, extracts relevant variant indices,\n",
        "        and performs the appropriate action based on the query intent.\n",
        "        Adds the user's query and the system's response to the chat history.\n",
        "\n",
        "        Args:\n",
        "            b (Button): Button widget that triggered the event\n",
        "        \"\"\"\n",
        "        query = self.query_input.value\n",
        "        if query and self.pipeline:\n",
        "\n",
        "            # Add the user's message to the chat\n",
        "            self.add_message_to_chat(query, is_user=True)\n",
        "\n",
        "            # Clear the input\n",
        "            self.query_input.value = ''\n",
        "\n",
        "            # Process the query\n",
        "            with self.print_output:\n",
        "                clear_output()\n",
        "                print(\"Processing your query...\")\n",
        "\n",
        "            # Detect intent\n",
        "            intent = self._detect_intent(query)\n",
        "            try:\n",
        "                if intent[\"compare_variants\"]:\n",
        "                    # Compare the 2 specified variants\n",
        "                    indices = self._extract_variant_indices_for_comparison(query, len(self.pipeline.variants)) # extract indices of specified variants to compare\n",
        "                    if len(indices) == 2:\n",
        "                        reports = self._get_reports_for_variants(indices)\n",
        "                        if isinstance(reports,int):\n",
        "                          idx=reports\n",
        "                          with self.print_output:\n",
        "                            clear_output()\n",
        "                            print(f\"Report not found for variant {idx+1}. If you would like me to analyse variant {idx+1} now, in order to be able to conduct the comparison: Please write 'Analyse variant {idx+1}.'\")\n",
        "                          self.add_message_to_chat(f\"Report not found for variant {idx+1}. If you would like me to analyse variant {idx+1} now, in order to be able to conduct the comparison: Please write 'Analyse variant {idx+1}.'\"\n",
        "                          , is_user=False)\n",
        "                          return\n",
        "                        if all(reports):\n",
        "                            response = self.pipeline.text_generator.generate_comparison_report(query, reports, indices)\n",
        "                            self.add_message_to_chat(response, is_user=False)\n",
        "                        else:\n",
        "                          self.add_message_to_chat(\"I couldn't find reports for both variants.\", is_user=False)\n",
        "                    else:\n",
        "                        self.add_message_to_chat(\"Please specify two variants to compare.\", is_user=False)\n",
        "\n",
        "                elif intent[\"plot_segment_nt_results\"]:\n",
        "                    # Plot the last SegmentNT results\n",
        "                    with self.print_output:\n",
        "                        self.plot_segment_nt_results()\n",
        "                        self.add_message_to_chat(f\"The SegmentNT results have been plotted and saved to: {self.output_dir} directory\", is_user=False)\n",
        "\n",
        "                elif intent[\"variant_analysis\"]:\n",
        "                    # Run variant analysis pipeline on specified variant\n",
        "                    idx = self._extract_variant_index_from_query(query, len(self.pipeline.variants)) # extract index of specified variant\n",
        "                    if not hasattr(self.pipeline, 'model') or self.pipeline.model is None:\n",
        "                        with self.print_output:\n",
        "                            print(\"Loading SegmentNT model...\")\n",
        "                            self.pipeline.load_model()\n",
        "\n",
        "                    with self.print_output:\n",
        "                        clear_output()\n",
        "                        self.add_message_to_chat(\n",
        "                                f\"Analyzing Variant {idx + 1} based on your query...\",\n",
        "                                is_user=False)\n",
        "                        print(\"Preparing altered genome based on variant selected...\")\n",
        "                        self.pipeline.prepare_altered_genome(idx)\n",
        "\n",
        "                        print(\"Running SegmentNT analysis...\")\n",
        "                        self.pipeline.run_segment_nt()\n",
        "\n",
        "                        print(\"Querying additional info about the variant to ClinVar...\")\n",
        "                        self.pipeline.query_clinvar()\n",
        "\n",
        "                        # Generate a report\n",
        "                        print(\"Generating analysis report...\")\n",
        "                        report = self.pipeline.generate_reports(query, output_dir=self.output_dir)\n",
        "                    with self.print_output:\n",
        "                        clear_output()\n",
        "                        print(\"Analysis complete!\")\n",
        "                        print(display(Markdown(report)))\n",
        "                        self.add_message_to_chat(f\"The report has been generated and saved to {self.output_dir}.\", is_user=False)\n",
        "\n",
        "                else:\n",
        "                    search_results = self.pipeline.text_generator.ask_agent(query, self.pipeline.current_analysis)\n",
        "                    self.add_message_to_chat(search_results, is_user=False)\n",
        "\n",
        "            except Exception as e:\n",
        "                with self.print_output:\n",
        "                    clear_output()\n",
        "                    print(f\"Error processing query: {str(e)}\")\n",
        "                # Add an error message to the chat\n",
        "                self.add_message_to_chat(\n",
        "                    f\"I'm sorry, I encountered an error while processing your query: {str(e)}\",\n",
        "                    is_user=False)\n",
        "\n",
        "    def on_clear_chat_button_click(self, b):\n",
        "        \"\"\"\n",
        "        Handle clear chat button click events.\n",
        "\n",
        "        Clears the chat history and resets the chat display.\n",
        "        Removes all messages from the chat container and initializes it again.\n",
        "\n",
        "        Args:\n",
        "            b (Button): Button widget that triggered the event\n",
        "        \"\"\"\n",
        "        self.chat_history = []\n",
        "\n",
        "        with self.chat_output:\n",
        "            clear_output()\n",
        "            display(HTML(self.style + \"<div class='chat-container' id='chat-container'></div>\"))\n",
        "\n",
        "    def _format_chat_history_for_download(self):\n",
        "        \"\"\"\n",
        "        Format chat history for download.\n",
        "\n",
        "        Converts the chat history to a formatted text representation\n",
        "        with timestamps, user/assistant indicators, and message content.\n",
        "\n",
        "        Returns:\n",
        "            str: Formatted chat history as text\n",
        "        \"\"\"\n",
        "        formatted_chat = []\n",
        "        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "        for msg in self.chat_history:\n",
        "            user = \"User\" if msg['is_user'] else \"Assistant\"\n",
        "            formatted_chat.append(f\"[{timestamp}] {user}: {msg['content']}\")\n",
        "\n",
        "        return \"\\n\\n\".join(formatted_chat)\n",
        "\n",
        "    def _download_text_file(self, text, filename):\n",
        "        \"\"\"\n",
        "        Create a downloadable text file using HTML anchor and Blob.\n",
        "\n",
        "        Generates JavaScript code that creates a Blob object from the text,\n",
        "        creates a download link, and triggers the download automatically.\n",
        "\n",
        "        Args:\n",
        "            text (str): Text content to download\n",
        "            filename (str): Name of the file to download\n",
        "\n",
        "        Returns:\n",
        "            Javascript: JavaScript code for file download\n",
        "        \"\"\"\n",
        "        # Convert text to a JavaScript-safe format\n",
        "        js_safe_text = text.replace(\"\\n\", \"\\\\n\").replace(\"'\", \"\\\\'\").replace('\"', '\\\\\"')\n",
        "\n",
        "        js_code = f\"\"\"\n",
        "        (function() {{\n",
        "            var text = \"{js_safe_text}\";\n",
        "            var blob = new Blob([text], {{type: 'text/plain'}});\n",
        "            var anchor = document.createElement('a');\n",
        "            anchor.href = window.URL.createObjectURL(blob);\n",
        "            anchor.download = \"{filename}\";\n",
        "            anchor.style.display = 'none';\n",
        "            document.body.appendChild(anchor);\n",
        "            anchor.click();\n",
        "            document.body.removeChild(anchor);\n",
        "            window.URL.revokeObjectURL(anchor.href);\n",
        "        }})();\n",
        "        \"\"\"\n",
        "\n",
        "        return Javascript(js_code)\n",
        "\n",
        "    def on_download_chat_button_click(self, b):\n",
        "        \"\"\"\n",
        "        Handle download chat button click events.\n",
        "\n",
        "        Saves the chat history to a file and provides download instructions.\n",
        "        Formats the chat history, saves it to a file in the output directory,\n",
        "        and informs the user of the file location.\n",
        "\n",
        "        Args:\n",
        "            b (Button): Button widget that triggered the event\n",
        "        \"\"\"\n",
        "        with self.print_output:\n",
        "            clear_output()\n",
        "            print(\"Saving chat history...\")\n",
        "\n",
        "        with self.print_output:\n",
        "            # Get formatted chat history text\n",
        "            chat_text = self._format_chat_history_for_download()\n",
        "\n",
        "            # Save to system\n",
        "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "            filename = os.path.join(self.output_dir, f\"chat_history_{timestamp}.txt\")\n",
        "\n",
        "            with open(filename, \"w\") as f:\n",
        "                f.write(chat_text)\n",
        "\n",
        "        with self.print_output:\n",
        "            clear_output()\n",
        "            print(f\"Chat history saved to '{filename}' in the notebook directory.\")\n",
        "            print(\"You can download it from the 'Output' tab in the sidebar.\")\n",
        "\n",
        "    def add_message_to_chat(self, message, is_user=True):\n",
        "        \"\"\"\n",
        "        Add a message to the chat history and update the display.\n",
        "\n",
        "        Appends a new message to the chat history, updates the chat display\n",
        "        with the complete history, and applies appropriate styling based on\n",
        "        whether the message is from the user or the assistant.\n",
        "\n",
        "        Args:\n",
        "            message (str): Message content to add\n",
        "            is_user (bool, optional): True if the message is from the user, False otherwise\n",
        "        \"\"\"\n",
        "        # Add the message to the history\n",
        "        self.chat_history.append({\n",
        "            'content': message,\n",
        "            'is_user': is_user\n",
        "        })\n",
        "\n",
        "        # Update the chat display\n",
        "        with self.chat_output:\n",
        "            clear_output()\n",
        "\n",
        "            chat_html = self.style\n",
        "            chat_html += \"<div class='chat-container' id='chat-container'>\"\n",
        "\n",
        "            for msg in self.chat_history:\n",
        "                if msg['is_user']:\n",
        "                    chat_html += f\"<div class='user-message'>You: {msg['content']}</div>\"\n",
        "                else:\n",
        "                    chat_html += f\"<div class='bot-message'>Assistant: {msg['content']}</div>\"\n",
        "\n",
        "            chat_html += \"</div>\"\n",
        "\n",
        "            display(HTML(chat_html))\n",
        "\n",
        "    def _detect_intent(self, query):\n",
        "        \"\"\"\n",
        "        Detect the intent of a user query.\n",
        "\n",
        "        Analyzes the query text to determine what kind of operation the user\n",
        "        is requesting. Identifies intents like variant analysis, asking the\n",
        "        agent questions, plotting results, or comparing variants.\n",
        "\n",
        "        Args:\n",
        "            query (str): User's query text\n",
        "\n",
        "        Returns:\n",
        "            dict: Intent classification dictionary with boolean values for each intent\n",
        "        \"\"\"\n",
        "        query = query.lower()\n",
        "\n",
        "        intent = {\n",
        "        \"variant_analysis\": any(word in query for word in ['analyse', 'analyze']) and any(word in query for word in ['variant', 'variants']),\n",
        "        \"ask_agent\": any(word in query for word in ['search', 'what', 'where', 'how', 'why']) or '?' in query,\n",
        "        \"plot_segment_nt_results\": \"plot\" in query and (\"segmentNT\" in query or \"results\" in query),\n",
        "        \"compare_variants\": \"compare\" in query and any(word in query for word in ['variant', 'variants'])\n",
        "    }\n",
        "        return intent\n",
        "\n",
        "    def _extract_variant_index_from_query(self, query, total_variants):\n",
        "        \"\"\"\n",
        "        Extract a variant index (0-based) from a user query.\n",
        "\n",
        "        Identifies variant references like \"variant 1\", \"first variant\", etc.\n",
        "        Supports both numeric and ordinal variant references.\n",
        "\n",
        "        Args:\n",
        "            query (str): User's query text\n",
        "            total_variants (int): Total number of available variants\n",
        "\n",
        "        Returns:\n",
        "            int: 0-based variant index (defaults to 0 if no valid index is found)\n",
        "        \"\"\"\n",
        "        # Match \"variant 1\", \"variant 2\", etc.\n",
        "        match = re.search(r'variant\\s*(\\d+)', query, re.IGNORECASE)\n",
        "        if match:\n",
        "            idx = int(match.group(1)) - 1\n",
        "            if 0 <= idx < total_variants:\n",
        "                return idx\n",
        "\n",
        "        # Handle \"first\", \"second\", \"third\", etc.\n",
        "        ordinal_map = {\n",
        "            \"first\": 0, \"second\": 1, \"third\": 2, \"fourth\": 3,\n",
        "            \"fifth\": 4, \"sixth\": 5, \"seventh\": 6, \"eighth\": 7, \"ninth\": 8, \"tenth\": 9\n",
        "        }\n",
        "        for word, idx in ordinal_map.items():\n",
        "            if word in query.lower() and idx < total_variants:\n",
        "                return idx\n",
        "\n",
        "        # Fallback: use the first variant\n",
        "        return 0\n",
        "\n",
        "    def _extract_variant_indices_for_comparison(self, query, total_variants):\n",
        "        \"\"\"\n",
        "        Extract variant indices (0-based) for comparison from a query.\n",
        "\n",
        "        Identifies and extracts multiple variant references for comparison.\n",
        "        Supports numeric variant references like \"variant 1 and variant 2\".\n",
        "\n",
        "        Args:\n",
        "            query (str): User's query text\n",
        "            total_variants (int): Total number of available variants\n",
        "\n",
        "        Returns:\n",
        "            list: List of up to 2 variant indices (0-based) for comparison\n",
        "        \"\"\"\n",
        "        matches = re.findall(r'(?:variant(?:s)?\\s*)?(\\d+)', query, re.IGNORECASE)\n",
        "        indices = []\n",
        "        for match in matches:\n",
        "            idx = int(match) - 1\n",
        "            if 0 <= idx < total_variants:\n",
        "                indices.append(idx)\n",
        "        return indices[:2]  # Return up to 2 indices for comparison\n",
        "\n",
        "    def _get_reports_for_variants(self, indices):\n",
        "        \"\"\"\n",
        "        Retrieve stored reports for specified variants.\n",
        "\n",
        "        Loads previously generated reports for specified variants from\n",
        "        the output directory.\n",
        "\n",
        "        Args:\n",
        "            indices (list): List of variant indices\n",
        "\n",
        "        Returns:\n",
        "            list: List of report contents for each variant\n",
        "        \"\"\"\n",
        "        reports = []\n",
        "        for idx in indices:\n",
        "            variant_id = str(self.pipeline.variants[idx].get(\"Canonical SPDI\", \"variant\")).replace(\":\", \"_\")\n",
        "            response_path = os.path.join(self.output_dir, f\"report_{variant_id}.txt\")\n",
        "            try:\n",
        "                with open(response_path, \"r\") as f:\n",
        "                    reports.append(f.read())\n",
        "            except FileNotFoundError:\n",
        "                return idx\n",
        "        return reports\n",
        "\n",
        "    def plot_segment_nt_results(self):\n",
        "        \"\"\"\n",
        "        Plot the SegmentNT results.\n",
        "\n",
        "        This function visualizes the predicted probabilities for various genomic features\n",
        "        from a SegmentNT analysis across a sequence window centered on a variant position.\n",
        "\n",
        "        The plot includes:\n",
        "        - Multiple subplots with 2 features per subplot\n",
        "        - Color-coded probability lines for each genomic feature\n",
        "        - A vertical red line indicating the variant position\n",
        "        - Proper labeling and formatting\n",
        "\n",
        "        The function retrieves analysis data from the pipeline, arranges features in a\n",
        "        specific order to match Figure 3 from the paper, and saves the plot to the output directory.\n",
        "        It also prints the probability values at the variant position.\n",
        "\n",
        "        Returns:\n",
        "            None. Displays the plot and saves it to the output directory.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if self.pipeline and self.pipeline.current_analysis:\n",
        "                if 'probabilities_all_segNT' not in self.pipeline.current_analysis:\n",
        "                    print(\"SegmentNT data is not available. Please run SegmentNT analysis first.\")\n",
        "                    return\n",
        "\n",
        "                # Get necessary data from pipeline\n",
        "                predicted_probabilities_all = self.pipeline.current_analysis.get(\"probabilities_all_segNT\", [])\n",
        "                features = self.pipeline.current_analysis.get(\"features_all_segNT\", [])\n",
        "                position = self.pipeline.current_analysis.get(\"position\")\n",
        "                seq_length = self.pipeline.current_analysis.get(\"sequence_length\")\n",
        "\n",
        "                # Filter order_to_plot to only include features we actually have\n",
        "                # order_to_plot = [feat for feat in features_rearranged if feat in features]\n",
        "                # if not order_to_plot:\n",
        "                #     print(\"No features to plot.\")\n",
        "                #     return\n",
        "\n",
        "                sc = 1.8\n",
        "                n_panels = len(features)\n",
        "                panels_per_subplot = 2\n",
        "                n_subplots = (n_panels + panels_per_subplot - 1) // panels_per_subplot  # Ceiling division\n",
        "\n",
        "                # set colors\n",
        "                colors = sns.color_palette(\"Set2\").as_hex()\n",
        "                colors2 = sns.color_palette(\"husl\").as_hex()\n",
        "\n",
        "                fig_width=8\n",
        "\n",
        "                # Create figure with appropriate dimensions\n",
        "                _, axes = plt.subplots(n_subplots, 1, figsize=(int(fig_width) * sc, (n_subplots + 4) * sc))\n",
        "\n",
        "                # Make sure axes is always an array, even if there's only one subplot\n",
        "                if n_subplots == 1:\n",
        "                    axes = [axes]\n",
        "\n",
        "                position_int = int(position) if position is not None else seq_length // 2\n",
        "\n",
        "                for n, feat in enumerate(features):\n",
        "                    feat_id = features.index(feat)\n",
        "                    prob_dist = predicted_probabilities_all[:, feat_id]\n",
        "                    # Use the appropriate subplot\n",
        "                    ax = axes[n // 2]\n",
        "                    try:\n",
        "                        id_color = colors[feat_id]\n",
        "                    except:\n",
        "                        id_color = colors2[feat_id - 8]\n",
        "\n",
        "                    # Create x-axis values corresponding to nucleotide indices\n",
        "                    x_values = np.arange(position - 5000, position + 5000) #change x values to go from position-5000 to position+5000\n",
        "                    ax.plot(\n",
        "                        x_values[:len(prob_dist)], #plot using x_values as x-coordinates of the data points. prob_dist[:len(x_values)] will contain the corresponding probability values.\n",
        "                        prob_dist[:len(x_values)],\n",
        "                        color=id_color,\n",
        "                        label=feat,\n",
        "                        linestyle=\"-\",\n",
        "                        linewidth=1.5,\n",
        "                    )\n",
        "                    ax.grid(False)\n",
        "                    ax.spines['bottom'].set_color('black')\n",
        "                    ax.spines['top'].set_color('black')\n",
        "                    ax.spines['right'].set_color('black')\n",
        "                    ax.spines['left'].set_color('black')\n",
        "\n",
        "                # Set the x and y-axis limits\n",
        "                for a in range(0, n_subplots):  # Change n_panels to n_subplots\n",
        "                    axes[a].set_xlim(position - 5000, position + 5000)\n",
        "                    axes[a].set_ylim(0, 1.05)\n",
        "                    axes[a].set_ylabel(\"Prob.\")\n",
        "                    axes[a].legend(loc=\"upper left\", bbox_to_anchor=(1, 1), borderaxespad=0)\n",
        "\n",
        "                   # Add vertical line to highlight the variant nucleotide at x = position\n",
        "                    axes[a].axvline(x=position, color='red', linestyle='--')\n",
        "\n",
        "                    if a != (n_subplots-1):  # Change n_panels to n_subplots\n",
        "                        axes[a].tick_params(axis='x', which='both', bottom=True, top=False, labelbottom=False)\n",
        "\n",
        "                # Set common x-axis label\n",
        "                axes[-1].set_xlabel(\"Nucleotides\")\n",
        "                axes[n_subplots-1].grid(False)\n",
        "                axes[n_subplots-1].tick_params(axis='y', which='both', left=True, right=False, labelleft=True, labelright=False)\n",
        "\n",
        "                axes[0].set_title(\"Probabilities predicted over all genomics features\", fontweight=\"bold\")\n",
        "\n",
        "                figure=plt.gcf()\n",
        "                plt.tight_layout()\n",
        "\n",
        "                # Get Canonical SPDI for filename\n",
        "                canonical_spdi = self.pipeline.current_analysis[\"variant\"].get(\"Canonical SPDI\", \"variant\")\n",
        "                canonical_spdi = canonical_spdi.replace(\":\", \"_\")\n",
        "\n",
        "                # Save the plot\n",
        "                plot_filename = os.path.join(self.output_dir, f\"plot_{canonical_spdi}.png\")\n",
        "                figure.savefig(plot_filename, bbox_inches='tight')\n",
        "\n",
        "                # Print probabilities for nucleotide at x = position\n",
        "                index_of_position = position - (position - 5000) # Calculate the index corresponding to the position\n",
        "                probabilities_at_position = predicted_probabilities_all[index_of_position]\n",
        "\n",
        "                with self.print_output:\n",
        "                    print(f\"Probabilities at position {position}:\")\n",
        "                    for i, feature in enumerate(features):\n",
        "                        print(f\"  {feature}: {probabilities_at_position[i]:.4f}\")\n",
        "                    # Display figure\n",
        "                    plt.show()\n",
        "                    plt.close(figure)  # Close the figure to free memory\n",
        "\n",
        "                print(f\"The SegmentNT results have been plotted and saved to: {plot_filename}\")\n",
        "\n",
        "            else:\n",
        "                print(\"Pipeline or analysis data not available.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            print(f\"Error plotting SegmentNT results: {str(e)}\")\n",
        "\n",
        "    def display_ui(self):\n",
        "        \"\"\"\n",
        "        Display the complete UI.\n",
        "\n",
        "        This function creates and renders the entire user interface for the VariantAInalyser\n",
        "        application using ipywidgets. It organizes the interface into several logical sections:\n",
        "\n",
        "        1. Header section with app title and description\n",
        "        2. API Configuration section for API keys\n",
        "        3. File Upload section for VCF files\n",
        "        4. Variant Information section to display variant details\n",
        "        5. Analysis Assistant section for chatbot interaction\n",
        "        6. Pipeline Output section for logging messages\n",
        "\n",
        "        Each section is styled with CSS classes for consistent appearance. The function also\n",
        "        adds JavaScript code to handle Enter key presses in the query input field.\n",
        "\n",
        "        The UI components include:\n",
        "        - Input fields for API keys\n",
        "        - File upload widget\n",
        "        - Text output areas\n",
        "        - Chat interface with history\n",
        "        - Action buttons\n",
        "\n",
        "        Returns:\n",
        "            None. Displays the UI in the current Kaggle notebook cell.\n",
        "        \"\"\"\n",
        "        # Create HTML header with improved styling\n",
        "        header_html = \"\"\"\n",
        "        <div class=\"app-header\">\n",
        "            <h1>ðŸ§¬ VariantAInalyser</h1>\n",
        "            <p>Advanced Genomic Variant Analysis with AI</p>\n",
        "            </div>\n",
        "            \"\"\"\n",
        "\n",
        "        # Create layout sections with new CSS classes\n",
        "        api_key_section = widgets.VBox([\n",
        "            widgets.HTML('<div class=\"section-header\">API Configuration</div>'),\n",
        "            widgets.HBox([self.api_key_input, self.apply_api_key_button]),\n",
        "            widgets.HBox([self.clinvar_key_input])  # Added ClinVar key input\n",
        "        ])\n",
        "        api_key_section.add_class(\"section\")\n",
        "\n",
        "        upload_section = widgets.VBox([\n",
        "            widgets.HTML('<div class=\"section-header\">Upload VCF File</div>'),\n",
        "            self.file_upload\n",
        "        ])\n",
        "        upload_section.add_class(\"section\")\n",
        "\n",
        "        variant_section = widgets.VBox([\n",
        "            widgets.HTML('<div class=\"section-header\">Variant Information</div>'),\n",
        "            self.vcf_info_output\n",
        "        ])\n",
        "        variant_section.add_class(\"section\")\n",
        "\n",
        "        chat_section = widgets.VBox([\n",
        "            widgets.HTML('<div class=\"section-header\">Analysis Assistant</div>'),\n",
        "            self.chat_output,\n",
        "            widgets.HBox([self.download_chat_button]),\n",
        "            widgets.HBox([self.query_input, self.send_button, self.clear_chat_button])\n",
        "        ])\n",
        "        chat_section.add_class(\"section\")\n",
        "\n",
        "        print_section = widgets.VBox([\n",
        "            widgets.HTML('<div class=\"section-header\">Pipeline Output</div>'),\n",
        "            self.print_output\n",
        "        ])\n",
        "        print_section.add_class(\"section\")\n",
        "\n",
        "        # Apply additional styles to widgets\n",
        "        self.query_input.add_class(\"input-field\")\n",
        "        self.send_button.add_class(\"button-primary\")\n",
        "        self.clear_chat_button.add_class(\"button-secondary\")\n",
        "\n",
        "        # Container for all components\n",
        "        main_container = widgets.VBox([\n",
        "            widgets.HTML(header_html),\n",
        "            api_key_section,\n",
        "            upload_section,\n",
        "            variant_section,\n",
        "            chat_section,\n",
        "            print_section  # Added print section\n",
        "        ])\n",
        "        main_container.add_class(\"genomic-app\")\n",
        "\n",
        "        # Apply overall styles\n",
        "        display(HTML(self.style))\n",
        "        display(main_container)\n",
        "\n",
        "        # Add JavaScript handler for Enter key\n",
        "        js_code = \"\"\"\n",
        "        document.addEventListener('keydown', function(event) {\n",
        "            if (event.key === 'Enter' && document.activeElement === document.querySelector('.input-field')) {\n",
        "                event.preventDefault();\n",
        "                IPython.notebook.kernel.execute(\"ui.on_send_button_click(None)\");\n",
        "            }\n",
        "        });\n",
        "        \"\"\"\n",
        "        display(HTML(f\"<script>{js_code}</script>\"))\n",
        "\n",
        "print(\"\\n\", \"-\" * 75)\n",
        "print(\"\\n ðŸ’» VariantAnalysisUI Class was successfully defined ! (3/3)\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-21T03:17:58.64832Z",
          "iopub.execute_input": "2025-04-21T03:17:58.648687Z",
          "iopub.status.idle": "2025-04-21T03:17:58.715487Z",
          "shell.execute_reply.started": "2025-04-21T03:17:58.648659Z",
          "shell.execute_reply": "2025-04-21T03:17:58.714435Z"
        },
        "id": "ajoUzCIhYYuI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ§¬ **Try out VariantAInalyser!**\n",
        "\n",
        "Now that all the classes have been successfully defined, run the cell below to experiment with the VariantAInalyser interface.\n",
        "\n",
        "Here is some guidance on how to use the interface to make the most out of it:\n",
        "\n",
        "\n",
        "1. **Setup**: Enter your Google API key and Clinvar API key (this one is optional) into their corresponding boxes and click \"Apply API Key/s\"\n",
        "2. **Upload Data**: Upload a VCF file containing genetic variants by clicking on the \"Upload VCF file\" button. You can download an example gzipped VCF folder containing multiple variants' VCF files from the official NCBI ClinVar webpage by clicking on this link: https://ftp.ncbi.nlm.nih.gov/pub/clinvar/vcf_GRCh38/clinvar_papu.vcf.gz.    \n",
        "**NOTE**: To create the altered genome, a reference genome (i.e. with no variant) is needed. The majority of the variants present in the previously linked VCF folder are present in the Y chromosome. As such, I have uploaded the reference genome of chromosome Y as a FASTA file in the Input directory under the \"/kaggle/input/example-chromosome-genome-fasta-file\" folder. The notebook directly links to this file whenever it needs the reference genome so there is no need to make any changes in the code. However, if you would like to test out a different VCF file with variants on other chromosomes, make sure to upload the genome of those chromosomes and change the path to the relevant one in the prepare_altered_genome() method.\n",
        "3. **Explore Variants**: View extracted variant information displayed on the interface\n",
        "4. **Ask Questions**: Use the chat to ask questions about your variants\n",
        "    Examples of questions to ask include (you can ask all of them and in this order if you would like to experience all the features offered by the interface):\n",
        "   - Please analyse in detail variant 1.\n",
        "   - Analyze (different spelling on purpose to check the how spelling-proof the intent function is) variant 7.\n",
        "   - Please plot the SegmentNT results.\n",
        "   - Can you explain the results generated in a simple and concise manner?\n",
        "   - You mentionned that the variant was located in the 5'UTR, what is that?\n",
        "   - Please compare variants 1 and 7. Is one more likely to be pathogenic than the other?\n",
        "6. **Download Results**: The generated analysis reports and plots are automatically saved into the output directory. You also have the possibility to download the chat history for future reference!"
      ],
      "metadata": {
        "id": "Tk_dDCIcYYuJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Run this cell to instantiate the VariantAInalyser interface and start using it !\n",
        "\n",
        "def setup_variant_analysis_ui():\n",
        "    \"\"\"Set up and return the Variant Analysis UI.\"\"\"\n",
        "    ui = VariantAnalysisUI()\n",
        "    ui.display_ui()\n",
        "    return ui\n",
        "\n",
        "ui = setup_variant_analysis_ui()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-21T03:19:27.638054Z",
          "iopub.execute_input": "2025-04-21T03:19:27.638379Z",
          "iopub.status.idle": "2025-04-21T03:19:27.71553Z",
          "shell.execute_reply.started": "2025-04-21T03:19:27.638356Z",
          "shell.execute_reply": "2025-04-21T03:19:27.714567Z"
        },
        "id": "Rya95thwYYuJ"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}